Introduction
The popular and intriguing game of Tic Tac Toe is played by two players on a board that is usually three by three squares. To form a line of three symbols in a horizontal, vertical, or diagonal orientation, players alternately put their symbols—typically "X" and "O"—into empty squares. The objective is to complete a line ahead of time. The simple rules and strategic options make Tic Tac Toe a quick and entertaining game for players of all ages..

Implementation
The Alpha-Beta and Min-Max algorithms for adversarial search and the Q-learning algorithm for reinforcement learning are examples of agents that are desirable to use. Each agent seeks to make the optimal decisions by taking into account a number of factors, including the quantity of movements, node exploration, and the overall amount of time required to finish the game.

Objectives
1.Create agents that play the game Tic Tac Toe using both reinforcement learning and adversarial search.
2.Using the Min-Max Algorithm, Alpha-Beta Pruning, and Q-learning techniques, develop three distinct AI agents.
3.Test each algorithm's performance by using these agents to play many Tic Tac Toe games.
4.When three consecutive symbols are arranged in a row, column, or diagonal in the game, players score points.
5.To evaluate the performance of each of the three algorithms, identify relevant metrics. Identify the more effective approach: reinforcement learning or adversarial searching.

Q learning
Based on the Bellman Equation, Q-Learning is a popular reinforcement learning technique. The agent seeks to determine which rules result in the optimal actions in order to maximize incentives. These are the top options based on prior experiences. The agent's objective is to increase the value of "Q," or the performance level, at each stage.

Reinforcement Learning
A machine learning method called reinforcement learning enables an agent to gain knowledge through collaborative experimentation. The agent gains new knowledge by examining its own interactions and behaviors in the given environment. 

Min-max Algorithm
To play Tic-Tac-Toe, the Min-Max approach generates a decision tree with every move that could be made and its outcome. After that, it recursively assesses each step to determine which provides the best result for the player.

At each level of the option tree, the method alternates between increasing and diminishing the game's outcome. For example, it determines the optimum move for the "X" player while optimizing the outcome on each level, assuming that the "O" player will also choose the best choice.

Each result is given a number by the algorithm; a lower number means that player "O" did better, and a larger number means that player "X" did better. The program then determines which move corresponds to the highest score for "X" or the lowest number for "O".
The computer can evaluate every move that might be made on the 3x3 grid in Tic-Tac-Toe and choose the best one. The computer finds it increasingly challenging to assess each option quickly as the game gets more complex because there are more options accessible. In this case, methods like Q-learning and Alpha-Beta pruning are useful for reducing the search area and improving the

a. Game theory and decision-making both employ this algorithm. It uses backtracking and recursion.
b. By assuming that the other player is making a sensible decision as well, it determines the player's optimal course of action.
c. Recursion is used to navigate the game tree.
d. Frequently utilized in two-player board games like tic tac toe and chess.
e. Our algorithm explores the entire game using Depth-First Search until it reaches the terminal node, where it takes a different course.

Alpha Beta
Alpha-beta pruning's primary goal is to decrease the total number of nodes in the search tree generated by the min-max algorithm. This approach is frequently utilized in two-player games that employ hostile search strategies. It generates the same moves as min-max when applied to a min-max tree, but it deftly removes branches that aren't crucial to determining the final outcome.

Deliverables
a. The Min-Max, Alpha-Beta, and Reinforcement Learning Agents utilized in the creation of the game Tic Tac Toe are explained in detail in a user documentation model.

b. The algorithms developed for the AI Agents are included in Python files that end in.py.

c. Click the provided URL to open the GitHub repository and view the Python code and associated files.

d. The presentation slides and the YouTube video, which clearly demonstrates how the project is being carried out, are available for your evaluation.

Evaluation  Methodology
Many crucial factors need to be considered while assessing AI agents' performance in Tic-Tac-Toe in order to provide a thorough evaluation.

Win Rate: The proportion of games won against a specific opponent is one of the most crucial performance indicators. An agent who performs better and is more successful also has higher strategic intelligence.

Average Moves per Game: This statistic calculates the average number of moves required to win or lose a game in order to assess the agent's effectiveness. A lower average shows that the agent can make decisions fast and carefully.

Training Time: How long it will take the AI agent to become proficient at Tic-Tac-Toe is a crucial factor to take into account. A shorter training period shows how quick and efficient the agent is.

Performance Against Various Opponents: The agent's capacity to adapt is assessed by examining how well it performs against a variety of opponents with different skill levels. This ensures that the agent will be able to easily handle a variety of playing styles and ability levels.

person-Like Behavior: In addition to winning games, a proficient AI bot should act like a person. This involves more than just going for the kill; it also involves using cunning strategies to thwart your opponent's advances. The whole gameplay experience is enhanced by the agent's human-like suppleness.







